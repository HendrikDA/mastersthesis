\chapter{Cycle 4}
\label{ch:cycle4}
The fourth and last cycle saw the prototype be cleaned up and prepared for the final review. The focus was shifted away from adding new concepts and toward making the existing architecture robust and deployable. The final product is a shippable piece of technology.

% Diagnosis
\section{Diagnosis}
\label{sec:cycle4_diagnosis}

The fourth and last cycle diagnoses that the system in its current state relied too heavily on LLMs for core precessing tasks. Importing XML data into the knowledge graph is a critical point of the application, and relying on an LLM to handle this parsing was not considered a good choice. XML is a standardized format and the export structure from Archi is sufficiently formalized to be handled deterministically. It was therefore agreed that a generalized parser should be used to parse incoming XML files into the knowledge graph, replacing the LLM at this critical point within the system's architecture.

A second critical issue concerned the querying method used to retrieve information from the knowledge graph. Although Cypher queries were generated by the LLM and tailored to the user's input, the approach struggled once the schema started changing due to additionally imported datasets. The main problem with this was the over reliance on a hardcoded schema description within the system's context, which the LLM used as a reference on how to structure the query. However, with an evolving heterogeneous knowledge graph, this approach became unreliable because the system implicitly guessed at the graph's structure rather than deriving it from the data.

Finally, the practitioners expressed a clear requirement for a deployment method that enables the prototype to run on any local machine. This was a prerequisite for the planned final review and required the system to become portable and the evaluation setup reproducible .

% Action Planning
\section{Action Planning}
\label{sec:cycle4_planning}
The goal of this cycle was to finalize the prototype and have it ready for the final review, where all three stakeholders would test and discuss the system together. Achieving this goal requires four concrete actions be completed in the cycle. First, the XML data had to be parsed via a generalized parser and deterministic parser, replacing the LLM-based implementation. Second, the schema-handling strategy had to be refactored so that the system could dynamically understand the current knowledge graph structure at runtime, rather than relying on hardcoded schema descriptions. Third, a containerized local environment had to be set up to allow the full architecture of the prototype to run on the practitioners' devices during the final review, with the exception of the LLM. On top of this, a controlled evaluation setup had to be prepared with various pre-filled knowledge graphs for the practitioners to experiment with.

% Action Taken
\section{Action Taken}
\label{sec:cycle4_actionTaken}
The LLM-based data parser was replaced by an out-of-the-box solution from Awesome Procedures On Cypher (APOC). Instead of having an LLM infer nodes and relationships from XML, the system was refactored to load Archi-exported XML via deterministic APOC procedures. In this approach, the XML structure is parsed and transformed into Cypher-based graph insertions in a consistent and reproducible manner. This directly addressed the scaling issue identified in Cycle 3: importing XML is a core system function and needs stable behavior across repeated runs and across different XML files.

The schema-handling strategy was updated away from the hardcoded variant. An intermediate implementation retrieved schema information via Neo4j’s built-in call \path{db.schema.visualization()}\footnote{Neo4j Schema Visualization: \url{https://neo4j.com/docs/operations-manual/current/procedures/}} and injected the result into the system context before text-to-Cypher generation. While this improved results compared to a fixed schema prompt, the output was still insufficient for robust query generation, particularly once multiple architecture diagrams with different structures were present in the knowledge grpah.

This problem was also improved via APOC. Rather than using Neo4j's built-in schema call, the schema retrieval was changed to a predefined APOC function \path{apoc.meta.schema()}\footnote{APOC Meta Schema: \url{https://neo4j.com/labs/apoc/4.1/overview/apoc.meta/apoc.meta.schema/}}. Compared to the previous schema call, the APOC call retrieves more detailed metadata about the schema, which is vital for the LLM's context. This ensures that the LLM understands how the knowledge graph is structured and how it may query it for the information requested by the user's prompt.

The local environment was prepared using Docker containers to support with a reproducible execution setup on any machine. The containerized setup comes equipped with a frontend, backend, MCP Server, the necessary information to connect to an Open AI model, as well as two local databases. The first database contains the SpeedParcel dataset, while the second database is a playground database that is pre-filled with textbook information only. This design created a controlled evaluation setup for two use cases: SpeedParcel provides a known structural reference dataset where the prototype can be tested against expected results, while the playground environment enables importing additional XML files, thus creating a proprietary knowledge graph.

The UI was also refined to support the final review workflow and to increase transparency. Improvements included the ability to upload XML files directly through the web application, toggling between the SpeedParcel and playground database, and adding a button to copy the generated Cypher query of each response, allowing the user to inspect the Cypher and raw data directly in Neo4j. Additional developer-facing convenience features were added, for example quick access to connection information and opening the Neo4j console. This will reduce friction when opening and connecting to Neo4j during evaluation. A minimal form of conversation memory was also introduced by storing the previous user input and system answer, enabling follow-up questions to refer to the immediately preceding turn.

A practical challenge emerged once the system supported user uploads: resetting the database into the default state. A full restore from Neo4j backup files occurs at container level and would require command-line operations by the user, which was not appropriate for the intended evaluation workflow. Several alternatives were explored, including dumping the textbook graph into Cypher scripts and replaying them into the database. However, this proved inefficient due to file size and runtime constraints. The final solution therefore implemented a reset mechanism that deletes all nodes and relationships that do not belong to the textbook which is loaded by default, thus restoring the playground database while keeping the reference textbook intact.

Finally, portability was validated through a fresh installation outside the researcher's development environment. The prototype was installed on a separate machine and the installation documentation was updated accordingly. This acted as a practical test of the deployment quality and reduced the risk of environment-specific errors on either of the practitioners' devices during the final review.


% Evaluation
\section{Evaluation}
\label{sec:cycle4_evaluation}
The refactored prototype was reviewed by both advisors through their own internal testing using the example data. The review focused on whether the system was executable, stable, and suitable for the final workflow. In particular, the practitioners assessed whether the prototype could import XML data, generate usable Cypher queries in the presence of a changing schema, and answer the three categories of questions defined earlierl. The replacement of the LLM-based XML parser with a generalized APOC-based parser and the schema refactoring toward \path{apoc.meta.schema()} were assessed positively, as both changes increased reliability and reduced failure cases caused by a changing schema. A major milestone of this cycle was that the prototype was able to answer all three question categories for the first time in a consistent manner across repeated tests.

The containerized deployment was also evaluated implicitly as part of this cycle’s readiness check. The prototype stack was executed via Docker, the two-database setup was tested, and the UX improvements were validated in the intended review flow by toggling the datasets, uploading XML, and copying Cypher into the Neo4j console. The database reset mechanism was considered adequate for producing repeatable evaluation conditions. Overall, the advisors confirmed that a “definition of done” had been reached for the prototype phase: the system was not meant to be endlessly expanded before evaluation, but instead to be stabilized and prepared for the final review. This goal was achieved with the end of the fourth cycle.

Beyond the technical assessment, the cycle review also produced forward-looking implications. The practitioners emphasized the value of local execution for compliance reasons when working with real world data and discussed potential future deployment alternatives such as Podman in work environments where Docker may be restricted.

% Learning
\section{Learning}
\label{sec:cycle4_learning}
Many learnings can be taken from this last cycle. The first is that replacing LLM-based parsing with a generalized XML parser improved correctness, stability, and reproducibility when generating a knowledge base and retrieving information from it. This matters specifically because importing data into the knowledge graph is a central requirement of a system that is meant to support enterprise architects in their daily work. If importing behaves non-deterministically, the resulting knowledge graph may cause problems downstream.

The second main learning of this cycle was that text-to-Cypher generation is only viable when the LLM has an accurate view of the current schema. In earlier cycles, Cypher generation appeared straightforward because the SpeedParcel schema was stable and explicitly known. Once user-imported data was added, the schema became heterogeneous and partially unknown at runtime. This made it clear that hard-coded schema prompts do not fulfill this requirement. The approach was therefore improved by retrieving the current schema directly from the database and injecting it into the system context. Replacing Neo4j’s built-in schema visualization with the APOC equivalent improved the quality of the schema information and made Cypher generation more reliable across the playground datasets. A direct outcome of this refactoring was that the system could answer all three categories of questions consistently for the first time. This included conceptual, descriptive, and integrative questions of various kinds.

A remaining challenge that became very visible in this cycle is making Cypher generation independent of a specific data model. While schema retrieval reduces hardcoded contexts, it does not fully solve the problem. In order to navigate unfamiliar structures purely from the schema's meta information, the system prompt, and the user's prompt, the LLM is still tasked with in-context learning, as described by Zhao et al. (2024) \cite{zhao2024retrieval} in section \ref{sec:intro:relatedWork}.

With the conclusion of this cycle, \prototype{} was born into existence as a finished prototype, ready to be tested during the final review. This is also where the stakeholders agreed that the definition of done was achieved. Rather than endlessly expanding functionality, the work shifted toward freezing a stable, deployable state that can be evaluated fairly under reproducible conditions.

% Conclusion Paragraph
As described during the four development cycles, it becomes clear why Action Research was an invaluable methodology. From unclear beginnings containing only a vague vision for a final prototype, each development cycle contributed to the final architecture, allowing the end goal to become clearer and more goal oriented. Each phase helped examine what was technically possible and how the next iteration should be shaped based on practitioner feedback. This supported the exploratory nature of the project while still moving toward a defined artifact which is ready for the final review. In Cycle 4 specifically, this progress took the form of stabilizing the prototype around deterministic imports, schema-aware querying, and portable deployment. The next chapter takes a look at how the final review was conducted and what the learnings from it are.


