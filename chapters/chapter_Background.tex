\chapter{Terminology and Technology}
\label{ch:background}
This chapter goes in detail on the terminology and technology that will be relevant for the reader to have a foundational understanding of the rest of this thesis. Later chapters will build upon these concepts and pieces of technology.

%%%
% Enterprise Architecture Terminology
%%%
\section{Enterprise Architecture Terminology}
\label{sec:background:terminology}

\subsection{Enterprise Architecture Management}
\label{sub:background:eam}
Enterprise Architecture Management (EAM) can be summarized as being the bridge between the business and IT departments of an enterprise. The goal is to implement information technology that is aligned with the business needs of the company. This is in contrast to the IT department implementing information technology for the sake of implementing information technology, which people in IT are often fond of doing \cite{ahmed2017motivating}. An unwanted situation would then be when the IT department falls into a siloed way of thinking where they are decoupled from the rest of the company. EAM helps to ensure that the implemented information technology is achieving the right things, namely supporting the business capabilities and processes. \cite[pg. 2-3]{jung2021masterclass}

Enterprise Architecture can benefit a company in various ways. 

% How can this be achieved? what does EAM do in detail?

Diese Quelle hierfür vielleicht verwenden: \cite{jung2019purpose} Die Quelle hat vor allem eine Menge Fragen aus der echten welt, was EAs sich im alltag fragen. diese liste kann als referenz dienen für meinen copilot. Diese Quelle hilft da vielleicht auch nochmal um in die Tiefe zu gehen. \cite{castro2021towards}

\subsection{Enterprise Architect}
\label{sub:background:ea}

A common challenge for an EA is dealing with the heterogenous nature of an application landscape \cite[pg. 6]{jung2021masterclass}

Erwähnen, dass eine Herausforderung des EAs es ist, dass die vorzunehmenden Änderungen zwar von einem high-level POV einfach aussehen, aber in den details viele herausforderungen stecken. zB stakeholder management (jede Applikation hat einen eigenen verantwortlichen, viele schnittstellen der applikationen, etc.)

\subsection{Business Capabilities}
\label{sub:background:capabilities}

% All main types of architecture diagrams, such as application landscapes, capability maps, CS-Matrix, etc.
\subsection{Architecture Diagrams}

\subsubsection{Application Landscape}
\label{subsub:background:landscape}

\subsubsection{EAM Modeling Tool - Archi}
\label{subsub:background:archi}


%%%
% Technology
%%%
\section{Technology}
\label{sec:background:technology}
The following descriptions of technologies will help the reader to later understand the implementation details. They serve as a high-level, but sufficient, description of each.


\subsection{Large Language Models}
\label{sub:background:llms}
A Large Language Models (LLM)

LLMs are capable of supporting in language-related tasks where text needs to be generated, translated, summarized, analysed, or questions answered \cite{hadi2023large}.

\cite{singhal2023large} describes what llms are and why they are not good with domain specific information and how that causes them to hallucinate.


\subsection{Graph Databases, Neo4j, and Knowledge Graphs}
\label{sub:background:graphdb}


\subsection{Retrieval Augmented Generation}
\label{sub:background:rag}


\subsection{Model Context Protocol}
\label{sub:background:mcp}
Modern AI applications are typically designed to be connected with further external tools and services, such as a Neo4j database, in order to allow the AI to xyz to do. However, this brings the challenge with it that the developers of the proprietary application must manually define interfaces in order to connect their AI application to these external services. If the AI application is to be connected with \textit{n} external services, then it needs \textit{n} custom-built connections; one for each service. This comes with a lot of overhead, makes interoperability difficult to achieve, and can hinder long-term maintainability of a system. \cite{hou2025model, anthropic_mcp_2025}

This is where the Model Context Protocol (MCP), developed by Anthropic and released in 2024, comes into play. It standardizes the interface between an AI application and its connected external services by defining a structured protocol for tool discovery, invocation, and result handling. This allows a secure, two-way connection between the AI application and external tools. \cite{anthropic_mcp_2025} With an MCP server sitting between the MCP client (the AI application) and the external service, the MCP client only needs to communicate with the standardized MCP interface \cite{hou2025model}. 

Imagine an MCP client which leverages several external services such as an e-mail provider and calendar application. If a user prompt is sent to the MCP client with the request to create a calendar entry and send the calendar invite per email, then it must decide which of the external tools to invoke in order to fulfil this request. Based on the user's prompt, the MCP client decides which tool exposed by the MCP server should be invoked in order to fulfill the request. The MCP server is then able to invoke the API calls to these external services in order to fulfil the request, i.e. it is able to call the calendar application's API to create the calendar entry and then call the e-mail provider's API to send out the calendar invite. The results are then sent back to the MCP client. \cite{hou2025model} Without the MCP server, the AI application would have to have manually written interfaces to communicate with and handle the e-mail provider's API and the calendar application's API. 

The MCP server is able to offer this agnostic connection to external services, such as an e-mail provider or calendar application, by requiring the tool's providers to explicitly implement their services as MCP-compatible tool interfaces \cite{hou2025model}. There are many pre-built MCP servers offered that allow standardized communication to specific external tools. For example, Neo4j has an official, open source MCP Server. As described later in section \ref{sub:mcp}, this is the MCP server implemented for the prototype within this research. \cite{neo4j_mcp_2025}
