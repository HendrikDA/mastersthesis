\chapter{Terminology and Technology}
\label{ch:background}
This chapter goes in detail on the terminology and technology that will be relevant for the reader to have a foundational understanding of the rest of this thesis. Later chapters will build upon these concepts and pieces of technology.

\section{Terminology}
\label{sec:background:terminology}

\subsection{Enterprise Architecture Management}
\label{sub:background:eam}
Enterprise Architecture Management (EAM) can be summarized as being the bridge between the business and IT departments of an enterprise. The goal is to implement information technology that is aligned with the business needs of the company. This is in contrast to the IT department implementing information technology for the sake of implementing information technology, which people in IT are often fond of doing \cite{ahmed2017motivating}. An unwanted situation would then be when the IT department falls into a siloed way of thinking where they are decoupled from the rest of the company. EAM helps to ensure that the implemented information technology is achieving the right things, namely supporting the business capabilities and processes. \cite[pg. 2-3]{jung2021masterclass}

Enterprise Architecture can benefit a company in various ways. 

% How can this be achieved? what does EAM do in detail?

Diese Quelle hierfür vielleicht verwenden: \cite{jung2019purpose} Die Quelle hat vor allem eine Menge Fragen aus der echten welt, was EAs sich im alltag fragen. diese liste kann als referenz dienen für meinen copilot. Diese Quelle hilft da vielleicht auch nochmal um in die Tiefe zu gehen. \cite{castro2021towards}

\subsection{Enterprise Architect}
\label{sub:background:ea}

A common challenge for an EA is dealing with the heterogenous nature of an application landscape \cite[pg. 6]{jung2021masterclass}

Erwähnen, dass eine Herausforderung des EAs es ist, dass die vorzunehmenden Änderungen zwar von einem high-level POV einfach aussehen, aber in den details viele herausforderungen stecken. zB stakeholder management (jede Applikation hat einen eigenen verantwortlichen, viele schnittstellen der applikationen, etc.)

\subsection{Business Capabilities}
\label{sub:background:capabilities}

% All main types of architecture diagrams, such as application landscapes, capability maps, CS-Matrix, etc.
\subsection{Architecture Diagrams}

\subsubsection{Application Landscape}
\label{subsub:background:landscape}

\subsubsection{EAM Modeling Tool - Archi}
\label{subsub:background:archi}


\section{Technology}
\label{sec:background:technology}


\subsection{Large Language Models}
\label{sub:background:llms}

LLMs are capable of supporting in language-related tasks where text needs to be generated, translated, summarized, analysed, or questions answered \cite{hadi2023large}.

\cite{singhal2023large} describes what llms are and why they are not good with domain specific information and how that causes them to hallucinate.

% Architecture of LLMs

\subsection{Graph Databases and Knowledge Graphs}
\label{sub:background:graphdb}


\subsection{Retrieval Augmented Generation}
\label{sub:background:rag}


\subsection{neo4j and the Cypher Query Language}
\label{sub:background:neo4j}


\subsection{Model Context Protocol}
\label{sub:background:mcp}
Modern AI applications are typically designed to be connected with further external tools and services, such as a Neo4j database, in order to allow the AI to xyz to do. However, this brings the challenge with it that the developers of the proprietary application must manually define interfaces in order to connect their AI application to these external services. If the AI application is to be connected with \textit{n} external services, then it needs \textit{n} custom-built connections; one for each service. This comes with a lot of overhead, makes interoperability difficult to achieve, and can hinder long-term maintainability of a system. \cite{hou2025model, anthropic_mcp_2025}

This is where the Model Context Protocol (MCP), developed by Anthropic and released in 2024, comes into play. It standardizes the interface between an AI application and its connected external services by defining a structured protocol for tool discovery, invocation, and result handling. This allows a secure, two-way connection between the AI application and external tools. \cite{anthropic_mcp_2025} With an MCP server sitting between the MCP client (the AI application) and the external service, the MCP client only needs to communicate with the standardized MCP interface \cite{hou2025model}. 

Imagine an MCP client which leverages several external services such as an e-mail provider and calendar application. If a user prompt is sent to the MCP client with the request to create a calendar entry and send the calendar invite per email, then it must decide which of the external tools to invoke in order to fulfil this request. Based on the user's prompt, the MCP client decides which tool exposed by the MCP server should be invoked in order to fulfill the request. The MCP server is then able to invoke the API calls to these external services in order to fulfil the request, i.e. it is able to call the calendar application's API to create the calendar entry and then call the e-mail provider's API to send out the calendar invite. The results are then sent back to the MCP client. \cite{hou2025model} Without the MCP server, the AI application would have to have manually written interfaces to communicate with and handle the e-mail provider's API and the calendar application's API. 

The MCP server is able to offer this agnostic connection to external services, such as an e-mail provider or calendar application, by requiring the tool's providers to explicitly implement their services as MCP-compatible tool interfaces \cite{hou2025model}. There are many pre-built MCP servers offered that allow standardized communication to specific external tools. For example, Neo4j has an official, open source MCP Server. As described later in section \ref{sub:mcp}, this is the MCP server implemented for the prototype within this research. \cite{neo4j_mcp_2025}

\subsection{XML and Transpilers}
\label{sec:background:transpilers}
% Important: only describe what XML and a transpiler is here. The methodology subsection will describe what and why the implementation was later.
As will be shown later in section xyz, the working prototype uses a domain-specific, source-to-source transpiler to turn the archimate-exported XML data into Cypher queries to insert the EA data into the graph database.

This source has a bit of good information on why XML is good as a structure language\cite{ruhlemann2017conversation} "Simply speaking, eXtensible Markup Language (XML) is a data architecture connecting meta-data and data. The architecture's defining feature is the hierar-chical network of nodes. Every node in the XML structure is connected somehow to any other node; also, being a hierarchy, every node is either subordinate or su-perordinate to another node, as shown in the tree structure in Figure 1. Further, XML "provides a standard syntax for the mark-up of data and documents" (Watt 2002:1). The syntax along with the hierarchical network structure make XML doc-uments exhaustively searchable and therefore useful for linguistic research."

More detailed information on the transpiler is described in section xyz.


\subsection{APOC and XPATH}
\label{sec:background:apoc}
Describe how apoc + xpath work and what this has to do with the neo4j cyphers. this might be better in the methodology section as a quick paragraph, but it has to be described somewhere.