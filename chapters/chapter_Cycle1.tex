\chapter{Cycle 1}
\label{ch:cycle1}
With the beginning of the first Action Research cycle, the development for the prototype began. The main goal of the first cycle was to produce a proof of concept which could be evaluated at the end in order to define next steps in the explorative development approach. This chapter will cover each of the five phases of the cycle.

% Diagnosis
\section{Diagnosis}
\label{sec:cycle1_diagnosis}
The first cycle required several meetings and discussions with the academic supervisor and the domain-expert in order to identify how an LLM-based system can support enterprise architects in their daily work. This initial vision lacked concrete technical formulation and the feasibility of natural language interaction with enterprise architecture data was unclear. A vague end-goal was formulate without knowing how to achieve it and if it would be technically possible.

The co-advisor outlined typical enterprise architecture workflows and the tools used to document and interact with architectural artifacts in practice. An initial idea was propsed of an AI-based black-box system capable of ingesting architecture data and deriving its own internal representations. The idea of this approach would be to have an LLM-based system at hand which is able to read in architecture data, process it by building its own mappings and representations of the data, and outputting the restuls. The achievability as well as academic applicability of such a black-box system were critically questioned, particularly because of the limited transparency of the inner mechanisms and how to test this. Leaving 100\% of the processing up to the LLM without be able to understand how the LLM would process it or how to build such a black-box system was deemed as an undesireable approach.

As an alternative, the academic supervisor proposed an explicit knowledge graph approach in which a knowledge graph is built and used to supplement LLM-generated answers. This differs from the black-box approach in that an explicit database is present and the interaction between the LLM and the database would be clear. This transparency aligns well with the mentioned advantages of a RAG-based LLM system in section \ref{ch:SOTA} by Zhao et al. (2024) \cite{zhao2024retrieval}.

The key distinction between the black-box and white-box approaches is the transparency. While the black-box approach autonomously creates an internal representation of the information, the white-box approach requires the manual design and implementation of an explicit technical architecture. These discussions were necessary in order to scope the solution space. Early visions of an end goals included a chatbot that would support enterprise architects in exploring and improving application landscapes, for example by identifying inconsistencies or incomplete application landscapes. At this stage, the research methodology had not yet been explicitly defined as Action Research, and it was initially assumed that the resulting prototype would be evaluated through an expert-interview.

With the vaguely defined goal of a RAG-based implementation, the first cycle's implementation phase began.

% Action Planning
\section{Action Planning}
\label{sec:cycle1_planning}
The goal for the first cycle was to create a proof of concept that would display the technical feasibility of a RAG-based LLM approach. This would require that a system be setup in a way that conversational data is supplemented via the access to a knowledge graph. The knowledge graph in the first step was to consist of enterprise architecture knowledge grounded in textbook-based domain information. The reason for choosing the textbook to fill the knowledge graph in this first step was twofold. First, the textbook information was readily available, while an example architecture dataset was not yet available. Second, a key requirement of the system would be that the chatbot is able to support in EAM decisions. This meant that the knowledge graph must be fed with information about enterprise architecture management and how to fulfill the role of an enterprise architect.

On top of this, it was also decided that a single-agent architecture will be used, as multi-agent architectures were considered unnecessarily complex for an initial proof of concept. Neo4j was decided to be the database of choice as well as the textbook \textit{Masterclass Enterprise Architecture Management} by authors Jung and Fraunholz 2021 \cite{jung2021masterclass} from chapter \ref{ch:SOTA}.

This approach corresponds to the research by Laurenzi et al. (2024) \cite{laurenzi2024llm} described in section \ref{sec:intro:relatedWork}. The questions being asked of the system are defined, meaning the knowledge graph may be filled with data before being tested and validated.

% Action Taken
\section{Action Taken}
\label{sec:cycle1_actionTaken}
After setting up a test database within Neo4j, it was possible to commence with filling the knowledge graph with data. The textbook consists of 213 pages of content found in PDF format. This meant that the PDF content, consisting of chapters, sections, headers, paragraphs, figures, etc. required being broken down into chunks that could be transformed into the required structure of the knowledge graph, nodes and edges. To support with this task, the parsing service LlamaIndex \footnote{LlamaParse: \url{https://www.llamaindex.ai/llamaparse}} was found during research. LlamaParse is able to parse common document types, such as PDF documents, and graphical representations of this data. On top of this, a GitHub repository by Joshua Yu \footnote{Joshua Yu's GitHup Repository: \url{https://github.com/Joshua-Yu/graph-rag/tree/main/openai\%2Bllamaparse}} was found, which utilizes LlamaParse in conjunction with OpenAI's LLM to parse PDF documents, create embeddings, and save them to a Neo4j database. Slight adjustments to the codebase were required to fit the structure of the textbook.

Once the knowledge graph was filled with the textbook information, validation of the data was done via Neo4j's interactive graph explorer. Samples of the knowledge graph were taken and compared to the contents of the textbook. It was evaluated whether nodes contained the information corresponding to the sections of the textbook and whether or not the nodes were connected with the other nodes that related to the same contents.

With a viable knowledge graph setup, the surrounding system was developed to be able to retrieve the information from the database. A browser-based application was setup via React\footnote{React: \url{https://react.dev/}} which presented the user with an input field and the conversation history of the user's prompt and resulting response of the LLM. The backend, consisting of Python, offered an endpoint for communication with the frontend and was connected to the Neo4j database.

The information retrieval from the database was then implemented by a fixed and parameterized cypher where the user's query was embedded and injected into the parameters of the cypher. This consisted of using an embedding model to convert the user's input into an embedding, which is a numerical vector representation of the text. This embedding is then used to retrieve similar embeddings within the knowledge graph. The idea of this is that if a user inputs a prompt asking for information about business capabilities, then the embedding will be near similar embeddings in the knowledge graph which may contain further information about business capabilities. The top \textit{k} embeddings were then returned, where different values for \textit{k} were tried out in attempt to strike a balance between returning just enough information from the knowledge graph to be able to answer the prompt without overloading the LLM with information. As a backup method, a simple keyword search of the user's prompt was also implemented.

The raw information retrieved from the knowledge graph is then fed into the LLM, allowing it to generate a natural language response which is presented to the user in the frontend.

The LLM used throughout was the Qwen2.5-7B-Instruct model \footnote{Qwen: \url{https://huggingface.co/Qwen/Qwen2.5-7B-Instruct}}. The reason choosing this model was that it allows a full local deployment without relying on an external model and is free to use.

The development of the current system was supported via generative AI.

% Evaluation
\section{Evaluation}
\label{sec:cycle1_evaluation}
The current state of the prototype contains the textbook information in the knowledge graph. The frontend and backend systems are able to take a user's input and retrieve subgraphs based on the embedding of the input. The retrieved information is generated into natural language by the LLM and presented to the user in natural language.

The state of the proof of concept after the first cycle was demonstrated to both advisors and evaluated qualitatively through open discussions. Example prompts were demonstrated, showing that information can be dynamically retrieved from the knowledge graph. Both advisors positively assessed the feasibility of the approach, and the co-advisor confirmed that an explicit knowledge graph-based solution will be a viable direction for further development.

However, the current implementation comes with many pitfalls and leaves much room for improvement in the later cycles. The first problem identified is the current querying method. While vector embedding is a viable way of retrieving information from a knowledge graph, it is less advantageous when dealing with structured knowledge within a knowledge graph. In the case of the current data, everything is semantically structured and logically interconnected. This means that a Cypher-based approach may be more advantageous.

Another challenge faced during the first cycle came from the applied approach of programming with the assistance of generative AI. While the development of this proof of concept was sped up with the assistance of generative AI, it was became clear that an over reliance on it meant that the code became unmaintainable without the help of the same AI. This dependence quickly impeded the development in the same pace as in the beginning. This was an early warning sign that the further development of the system should not be overreliant on generative AI.

Lastly, the current Qwen model was deemed to be too slow, with answers often taking minutes to process. This lead to the idea of testing alternative options as the LLM of choice.


% Learning
\section{Learning}
\label{sec:cycle1_learning}
Compared to the beginning of the cycle, in which the feasibility of a centralized knowledge graph was uncertain, the first cycle demonstrated that an explicit, white-box approach represents a practical path forward. With the current version of the prototype, it is possible to improve upon it and iteratively shape the direction taken to achieve the final product.

The cycle also revealed key challenges in three areas of the system. These areas are transforming data into graph structures, the extraction of relevant knowledge from the graph based on a user's input, and response generation time by the LLM.

On top of this, the risk of relying too heavily on an LLM arose by giving full control of critical points of the application to the LLM and thus being dependent on the capabilities of the language model.

Lastly, this cycle largely dealt with the challenge of breaking down the textbook into a knowledge graph. However, this challenge was unique to this cycle, as the textbook is now represented within the knowledge graph. Later changes made to the knowledge graph will not require parsing textbooks or PDF information, but rather parsing architecture data. This means that the textbook parsing was a one time ordeal.


This first cycle served well as a starting point. The lack of clarity in which direction the project should be taken was quickly cleared by the prototype. The first cycle has produced a prototype which can be built upon in the later cycles. The points of improvement identified in this cycle will serve as the input for the next cycles. It is thus evident that further iterations will be required to systematically address these challenges with an exploratory development process.