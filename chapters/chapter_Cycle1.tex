\chapter{Cycle 1}
\label{ch:cycle1}
With the beginning of the first Action Research cycle, development of the prototype commenced. The main goal of the first cycle was to produce a proof of concept that could be evaluated in order to define the subsequent steps within the exploratory development approach. This chapter covers each of the five phases of the cycle.

% Diagnosis
\section{Diagnosis}
\label{sec:cycle1_diagnosis}
The first cycle required several meetings and discussions with the academic supervisor and the domain-expert in order to identify how an LLM-based system could support enterprise architects in their daily work. This initial vision lacked a concrete technical formulation, and the feasibility of natural language interaction with enterprise architecture data remained unclear. A vague end-goal was formulated without knowing how to achieve it and if it would be technically possible.

The co-advisor outlined typical enterprise architecture workflows and the tools used to document and interact with architectural artifacts in practice. An initial idea was proposed: an AI-based black-box system capable of ingesting architecture data and deriving its own internal representations. The idea of this approach would be to have an LLM-based system at hand which is able to read in architecture data, process it by building its own mappings and representations, and producing the resulting outputs autonomously. The achievability as well as academic applicability of such a black-box system were critically questioned, particularly because of the limited transparency of the inner mechanisms and how to test this. Leaving 100\% of the processing up to the LLM without understanding how it performs this processing or how such a system would be engineered was deemed as an undesirable approach.

As an alternative, the academic supervisor proposed an explicit knowledge graph approach in which a knowledge graph is built and used to supplement LLM-generated answers. This differs from the black-box approach in that an explicit database is present and the interaction between the LLM and the database is clearly defined. This transparency aligns well with the mentioned advantages of a RAG-based LLM system in section \ref{ch:SOTA} by Zhao et al. (2024) \cite{zhao2024retrieval}.

The key distinction between the black-box and white-box approaches lies in their degree of transparency. While the black-box approach autonomously creates an internal representation of the information, the white-box approach requires the deliberate design and implementation of an explicit technical architecture. These discussions were necessary in order to scope the solution space. Early visions of an end goals included a chatbot capable of supporting enterprise architects in exploring and improving application landscapes, for example by identifying inconsistencies or incomplete architectural documentation. At this stage, the research methodology had not yet been explicitly defined as Action Research, and it was initially assumed that the resulting prototype would be evaluated through an expert interview.

With this still broadly defined goal of a RAG-based implementation, the implementation phase of the first cycle began.

% Action Planning
\section{Action Planning}
\label{sec:cycle1_planning}
The goal of the first cycle was to create a proof of concept demonstrating the technical feasibility of a RAG-based LLM approach. This required setting up a system in which conversational interaction is supplemented through access to a knowledge graph. In the first step, the knowledge graph was designed to consist of enterprise architecture knowledge grounded in textbook-based domain information. The decision to use the textbook as the initial knowledge source was twofold. First, the textbook information was readily available, whereas an example enterprise architecture dataset was not yet accessible. Second, a key requirement of the system was that the chatbot should support decision-making within EAM. Consequently, the knowledge graph needed to contain domain knowledge about enterprise architecture management and the responsibilities of an enterprise architect.

Furthermore, a single-agent architecture was selected, as multi-agent architectures were considered unnecessarily complex for an initial proof of concept. Neo4j was chosen as the database system, and the textbook \textit{Masterclass Enterprise Architecture Management} by Jung and Fraunholz (2021) \cite{jung2021masterclass}, introduced in chapter \ref{ch:SOTA}, served as the primary knowledge source during this cycle.

This approach corresponds to the research by Laurenzi et al. (2024) \cite{laurenzi2024llm} described in section \ref{sec:intro:relatedWork}. The questions posed to the system are predefined, allowing the knowledge graph to be populated with data prior to testing and validation.

% Action Taken
\section{Action Taken}
\label{sec:cycle1_actionTaken}
After setting up a test database within Neo4j, the knowledge graph was populated with data. The textbook consists of 213 pages of content found in PDF format. This required the PDF content, consisting of chapters, sections, headers, paragraphs, figures, etc. to be decomposed into chunks that could be transformed into the corresponding knowledge graph structure of nodes and relationships. To support with this task, the parsing service LlamaIndex \footnote{LlamaParse: \url{https://www.llamaindex.ai/llamaparse}} was found during research. LlamaParse is able to parse common document types, such as PDF documents, and graphical representations of this data. On top of this, a GitHub repository by Joshua Yu \footnote{Joshua Yu's GitHup Repository: \url{https://github.com/Joshua-Yu/graph-rag/tree/main/openai\%2Bllamaparse}} was found, which utilizes LlamaParse in conjunction with OpenAI's LLM to parse PDF documents, create embeddings, and save them to a Neo4j database. Minor adjustments to the codebase were required to align with the structure of the textbook.

Once the knowledge graph was filled with the textbook information, validation of the data was done via Neo4j's interactive graph explorer. Samples of the knowledge graph were taken and compared to the contents of the textbook. It was evaluated whether nodes contained the information corresponding to the sections of the textbook and whether or not the nodes were connected with the other nodes that related to the same contents.

With a viable knowledge graph setup, the surrounding system was developed to be able to retrieve the information from the database. A browser-based application was setup via React\footnote{React: \url{https://react.dev/}} which presented the user with an input field and the conversation history of the user's prompt and resulting response of the LLM. The backend, consisting of Python, offered an endpoint for communication with the frontend and was connected to the Neo4j database.

Information retrieval from the database was implemented using a fixed, parameterized Cypher query, into which the embedded representation of the userâ€™s query was injected as a parameter. This consisted of using an embedding model to convert the user's input into an embedding, which is a numerical vector representation of the text. This embedding was subsequently used to retrieve semantically similar embeddings within the knowledge graph via a vector similarity search. The underlying idea is that if a user submits a prompt concerning business capabilities, then the embedding will be near similar embeddings in the knowledge graph which may contain further information about business capabilities. The top \textit{k} embeddings were then returned, where different values for \textit{k} were tried out in attempt to strike a balance between returning just enough information from the knowledge graph to be able to answer the prompt without overloading the LLM with information. As a fallback mechanism, a simple keyword-based search of the user's prompt was also implemented.

The raw information retrieved from the knowledge graph is then fed into the LLM, allowing it to generate a natural language response which is presented to the user in the frontend. This allows the user to be presented with a natural language response instead of the raw information extracted from the database. This aligns with the prescribed goal of offering enterprise architects a chatbot to assist in their work.

The LLM used throughout was the Qwen2.5-7B-Instruct model \footnote{Qwen: \url{https://huggingface.co/Qwen/Qwen2.5-7B-Instruct}}. The reason choosing this model was that it allows a full local deployment without relying on an external model and is free to use.

The development of the system was supported through the use of generative AI tools.
% Evaluation
\section{Evaluation}
\label{sec:cycle1_evaluation}
The current state of the prototype contains the textbook information in the knowledge graph. The frontend and backend systems are able to take a user's input and retrieve subgraphs based on the embedding of the input. The retrieved information is generated into natural language by the LLM and presented to the user in natural language.

The proof of concept at the end of the first cycle was demonstrated to both advisors and evaluated qualitatively through open discussion. Demonstration prompts showed that conceptual questions, e.g. on the definitions of EAM concepts, were answered satisfactorily by retrieving the correct sections of the textbook from within the knowledge graph. However, the satisfactory retrieval process was not applicable to all types of conceptual questions and left room for improvement in the consistency.

Both advisors positively assessed the feasibility of the approach, and the co-advisor confirmed that an explicit knowledge graph-based solution will be a viable direction for further development. The prototype successfully demonstrated technical feasibility in that EAM knowledge can be represented in a graphical structure, user prompts can be used for retrieval of information within the knowledge graph, and that the retrieved information can be used as context in the LLM to generate domain-specific, natural language answers.

However, the current implementation comes with many pitfalls and leaves much room for improvement in the later cycles. The first problem identified is the current querying method. While vector embedding is a viable method for retrieving information, it is less advantageous when dealing with explicitly structured knowledge within a knowledge graph. In the case of the current data, everything is semantically structured and logically interconnected. In such cases, a deterministic Cypher-based retrieval approach may be more appropriate.

Another challenge faced during the first cycle came from the applied approach of programming with the assistance of generative AI. Although generative AI significantly accelerated the development of the proof of concept, it became evident that excessive reliance on it led to reduced code maintainability without continued AI assistance. This dependence quickly impeded further rapid development after the initial phase. This was an early warning sign that the further development of the system should not be overreliant on generative AI.

Lastly, the currently deployed Qwen model was deemed too slow, with answers often taking minutes to process. This led to the idea of testing alternative options as the LLM of choice.

The first cycle aligns closely with the six-step knowledge graph creation process proposed by Laurenzi et al. (2024) \cite{laurenzi2024llm}. In particular, the initial scoping discussions correspond to the types of questions the system should answer were implicitly defined. The manual construction of the graph structure and data ingestion reflect steps 2 through 5, including schema design via LlamaIndex, knowledge extraction from the textbook, validation via the Neo4j interface, and population of the graph.

% Learning
\section{Learning}
\label{sec:cycle1_learning}
Compared to the beginning of the cycle, where the feasibility of a centralized knowledge graph was uncertain, the first cycle demonstrated that an explicit white-box approach represents a viable path forward. The current version of the prototype offers a solid foundation upon which further iterations can build and refine the technical direction toward the final system. At the same time, the cycle also revealed several core challenges that must be addressed throughout later development cycles. These challenges include transforming data into graph structures, the extraction of relevant knowledge from the graph based on a user's input, and response generation time by the LLM.

Furthermore, the first cycle highlighted the risk of relying excessively on an LLM, particularly when the core application logic is left up to the supporting language model. This dependency during development limits the maintainability of the code and contradicts the white-box philosophy, as this reduces the transparency on a code-level.

Lastly, this cycle largely dealt with the challenge of breaking down the textbook into a knowledge graph. However, this challenge was unique to this cycle, as the textbook is now represented within the knowledge graph. Later changes made to the knowledge graph will not require parsing textbooks or PDF information, but rather parsing architecture data. Consequently, the textbook parsing represented a one-time effort rather than a recurring task.



This first cycle served well as a starting point. The lack of clarity in which direction the project should be taken was quickly cleared by the prototype. The first cycle has produced a prototype which can be built upon in the later cycles. The points of improvement identified in this cycle will serve as the input for the next cycles. It is therefore evident that further iterations are required to systematically address these challenges within an exploratory development process.

